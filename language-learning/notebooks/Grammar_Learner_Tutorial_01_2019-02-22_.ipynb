{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Jump-start\" data-toc-modified-id=\"Jump-start-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Jump start</a></span><ul class=\"toc-item\"><li><span><a href=\"#Basic-settings-and-imports\" data-toc-modified-id=\"Basic-settings-and-imports-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Basic settings and imports</a></span></li><li><span><a href=\"#Input:-&quot;parses&quot;-???\" data-toc-modified-id=\"Input:-&quot;parses&quot;-???-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Input: \"parses\" ???</a></span></li><li><span><a href=\"#LEARN!\" data-toc-modified-id=\"LEARN!-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>LEARN!</a></span></li></ul></li><li><span><a href=\"#Response:-re-=-learn_grammar(**kwargs)\" data-toc-modified-id=\"Response:-re-=-learn_grammar(**kwargs)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Response: <code>re = learn_grammar(**kwargs)</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Corpus-statistics:-re['corpus_stats']--⇒--corpus_stats.txt-file\" data-toc-modified-id=\"Corpus-statistics:-re['corpus_stats']--⇒--corpus_stats.txt-file-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Corpus statistics: <code>re['corpus_stats']</code>  ⇒  <code>corpus_stats.txt</code> file</a></span></li><li><span><a href=\"#Response-beyond-corpus_stats\" data-toc-modified-id=\"Response-beyond-corpus_stats-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Response beyond corpus_stats</a></span></li><li><span><a href=\"#Category-tree:-re['cat_tree_file']--⇒--cat_tree.txt-file\" data-toc-modified-id=\"Category-tree:-re['cat_tree_file']--⇒--cat_tree.txt-file-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Category tree: <code>re['cat_tree_file']</code>  ⇒  <code>cat_tree.txt</code> file</a></span></li><li><span><a href=\"#Link-Grammar-file:-re['grammar_file']--⇒--dict...dict-file\" data-toc-modified-id=\"Link-Grammar-file:-re['grammar_file']--⇒--dict...dict-file-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Link Grammar file: <code>re['grammar_file']</code>  ⇒  <code>dict...dict</code> file</a></span></li></ul></li><li><span><a href=\"#More-Turtle\" data-toc-modified-id=\"More-Turtle-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>More Turtle</a></span></li><li><span><a href=\"#Grammar-Learner-parameters:-kwargs\" data-toc-modified-id=\"Grammar-Learner-parameters:-kwargs-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Grammar Learner parameters: kwargs</a></span></li><li><span><a href=\"#Closer-to-reality\" data-toc-modified-id=\"Closer-to-reality-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Closer to reality</a></span><ul class=\"toc-item\"><li><span><a href=\"#Basic-settings\" data-toc-modified-id=\"Basic-settings-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Basic settings</a></span></li><li><span><a href=\"#Test-corpus-settings\" data-toc-modified-id=\"Test-corpus-settings-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Test corpus settings</a></span></li><li><span><a href=\"#Table:-pqa_table.py\" data-toc-modified-id=\"Table:-pqa_table.py-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Table: <code>pqa_table.py</code></a></span></li><li><span><a href=\"#Mutlti-line-table\" data-toc-modified-id=\"Mutlti-line-table-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Mutlti-line table</a></span></li><li><span><a href=\"#Real-&quot;Child-Directed-Speech&quot;-tests-~-3-hours-@-6-cores-of-12-core-CPU\" data-toc-modified-id=\"Real-&quot;Child-Directed-Speech&quot;-tests-~-3-hours-@-6-cores-of-12-core-CPU-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Real \"Child Directed Speech\" tests ~ 3 hours @ 6 cores of 12-core CPU</a></span></li></ul></li><li><span><a href=\"#More-Jupyter-notebook-samples:-Github\" data-toc-modified-id=\"More-Jupyter-notebook-samples:-Github-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>More Jupyter notebook samples: Github</a></span></li><li><span><a href=\"#Grammar-Learner-test-archives\" data-toc-modified-id=\"Grammar-Learner-test-archives-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Grammar Learner test archives</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# SingularityNET Unsupervised Language Learning  \n",
    "[GitHub.com/SingNET/Language-Learning](https://github.com/singnet/language-learning)  ⇒  [README](https://github.com/singnet/language-learning/blob/master/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar Learner  \n",
    "[GitHub.com/SingNET/Language-Learning/src/Grammar_Learner](https://github.com/singnet/language-learning/tree/master/src/grammar_learner)  ⇒ [README](https://github.com/singnet/language-learning/blob/master/src/grammar_learner/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Jump start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Basic settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:20:48.983034Z",
     "start_time": "2019-02-22T08:20:48.122466Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-22 08:20:48 UTC :: module_path: /home/obaskov/py/language-learning \n",
      "out_dir: /home/obaskov/py/language-learning/output/Grammar_Learner_Tutorial_2019-02-22\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path: sys.path.append(module_path)\n",
    "from src.grammar_learner.learner import learn_grammar\n",
    "from src.grammar_learner.utl import UTC\n",
    "out_dir = module_path + '/output/Grammar_Learner_Tutorial_' + str(UTC())[:10]\n",
    "kwargs = {'output_grammar': out_dir + '/1st_test'}\n",
    "print(UTC(), ':: module_path:', module_path, '\\nout_dir:', out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Input: \"parses\" ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:21:57.045040Z",
     "start_time": "2019-02-22T08:21:57.041110Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_grammar': '/home/obaskov/py/language-learning/output/Grammar_Learner_Tutorial_2019-02-22/1st_test',\n",
       " 'input_parses': '/home/obaskov/py/language-learning/data/POC-Turtle/MST-fixed-manually'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs['input_parses'] = module_path + '/data/POC-Turtle/MST-fixed-manually'\n",
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:22:39.326695Z",
     "start_time": "2019-02-22T08:22:39.315911Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuna isa fish .\n",
      "0 ###LEFT-WALL### 1 tuna\n",
      "1 tuna 2 isa\n",
      "2 isa 3 fish\n",
      "3 fish 4 .\n",
      "\n",
      "herring isa fish .\n",
      "0 ###LEFT-WALL### 1 herring\n",
      "1 herring 2 isa\n",
      "2 isa 3 fish\n",
      "3 fish 4 .\n",
      "\n",
      "tuna has fin .\n",
      "0 ###LEFT-WALL### 1 tuna\n",
      "1 tuna 2 has\n",
      "2 has 3 fin\n",
      "3 fin 4 .\n",
      "\n",
      "herring has fin .\n",
      "0 ###LEFT-WALL### 1 herring\n",
      "1 herring 2 has\n",
      "2 has 3 fin\n",
      "3 fin 4 .\n",
      "\n",
      "parrot isa bird .\n",
      "0 ###LEFT-WALL### 1 parrot\n",
      "1 parrot 2 isa\n",
      "2 isa 3 bird\n",
      "3 bird 4 .\n",
      "\n",
      "eagle isa bird .\n",
      "0 ###LEFT-WALL### 1 eagle\n",
      "1 eagle 2 isa\n",
      "2 isa 3 bird\n",
      "3 bird 4 .\n",
      "\n",
      "parrot has wing .\n",
      "0 ###LEFT-WALL### 1 parrot\n",
      "1 parrot 2 has\n",
      "2 has 3 wing\n",
      "3 wing 4 .\n",
      "\n",
      "eagle has wing .\n",
      "0 ###LEFT-WALL### 1 eagle\n",
      "1 eagle 2 has\n",
      "2 has 3 wing\n",
      "3 wing 4 .\n",
      "\n",
      "fin isa extremity .\n",
      "0 ###LEFT-WALL### 1 fin\n",
      "1 fin 2 isa\n",
      "2 isa 3 extremity\n",
      "3 extremity 4 .\n",
      "\n",
      "wing isa extremity .\n",
      "0 ###LEFT-WALL### 1 wing\n",
      "1 wing 2 isa\n",
      "2 isa 3 extremity\n",
      "3 extremity 4 .\n",
      "\n",
      "fin has scale .\n",
      "0 ###LEFT-WALL### 1 fin\n",
      "1 fin 2 has\n",
      "2 has 3 scale\n",
      "3 scale 4 .\n",
      "\n",
      "wing has feather .\n",
      "0 ###LEFT-WALL### 1 wing\n",
      "1 wing 2 has\n",
      "2 has 3 feather\n",
      "3 feather 4 .\n"
     ]
    }
   ],
   "source": [
    "with open(kwargs['input_parses'] + '/poc-turtle-parses-gold.txt', 'r') as f: \n",
    "    lines = f.read().splitlines()\n",
    "for line in lines[:]: print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### LEARN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:22:44.219739Z",
     "start_time": "2019-02-22T08:22:43.963648Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('start', '2019-02-22 08:22:43 UTC'),\n",
       "             ('learn_grammar', 'v.0.7.81231'),\n",
       "             ('project_directory',\n",
       "              '/home/obaskov/py/language-learning/output/Grammar_Learner_Tutorial_2019-02-22/1st_test'),\n",
       "             ('input files',\n",
       "              ['/home/obaskov/py/language-learning/data/POC-Turtle/MST-fixed-manually/poc-turtle-parses-gold.txt']),\n",
       "             ('corpus_stats',\n",
       "              [['Number of sentences    ', 12],\n",
       "               ['Maximum sentence length', 3],\n",
       "               ['Average sentence length', 3],\n",
       "               ['Number of unique words in sentences', 13],\n",
       "               ['Number of unique parsed words      ', 13],\n",
       "               ['Number of unique non-parsed [words]', 0],\n",
       "               ['Number of unique linked words      ', 13],\n",
       "               ['Number of unique non-linked words  ', 0],\n",
       "               ['Total  words count in sentences    ', 36],\n",
       "               ['Parsed words count in sentences    ', 36],\n",
       "               ['Non-parsed [words] in sentences    ', 0],\n",
       "               ['Non-linked words (excl.non-parsed) ', 0],\n",
       "               ['Average word count ', 3],\n",
       "               ['Unique links number', 19],\n",
       "               ['Total  links count ', 24],\n",
       "               ['Average link count ', 1.3],\n",
       "               ['Average links per linked word', 2],\n",
       "               ['Unique connectors number', 17],\n",
       "               ['Total  connectors count ', 48],\n",
       "               ['Average connector count ', 2.8],\n",
       "               ['Unique disjuncts number', 16],\n",
       "               ['Total  disjuncts count ', 36],\n",
       "               ['Average disjunct count ', 2.2],\n",
       "               ['Average disjunct length', 1.3],\n",
       "               ['Maximum disjunct length', 2],\n",
       "               ['Unique seeds number', 31],\n",
       "               ['Total  seeds count ', 36],\n",
       "               ['Average seed count ', 1.2]]),\n",
       "             ('terms', 'disjuncts'),\n",
       "             ('parsed_links', 36),\n",
       "             ('unique_links', 31),\n",
       "             ('unique_words', 13),\n",
       "             ('unique_terms', 16),\n",
       "             ('word-term_pairs', 31),\n",
       "             ('corpus_stats_file',\n",
       "              '/home/obaskov/py/language-learning/output/Grammar_Learner_Tutorial_2019-02-22/1st_test/corpus_stats.txt'),\n",
       "             ('category_learner', 'v.0.7.81231'),\n",
       "             ('vector_space_dim', 2),\n",
       "             ('silhouette', 0.8974816894026034),\n",
       "             ('inertia', 0.004335897519749409),\n",
       "             ('generalization', 'none: off'),\n",
       "             ('cat_tree_file',\n",
       "              '/home/obaskov/py/language-learning/output/Grammar_Learner_Tutorial_2019-02-22/1st_test/4_cat_tree.txt'),\n",
       "             ('grammar_file',\n",
       "              '/home/obaskov/py/language-learning/output/Grammar_Learner_Tutorial_2019-02-22/1st_test/dict_4C_2019-02-22_0007.4.0.dict'),\n",
       "             ('grammar_clusters', 4),\n",
       "             ('grammar_rules', 4),\n",
       "             ('finish', '2019-02-22 08:22:44 UTC'),\n",
       "             ('grammar_learn_time', '00:00:00')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_grammar(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Response: `re = learn_grammar(**kwargs)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:23:19.576968Z",
     "start_time": "2019-02-22T08:23:19.345333Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re = learn_grammar(**kwargs)\n",
    "type(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:23:41.680338Z",
     "start_time": "2019-02-22T08:23:41.676512Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['start', 'learn_grammar', 'project_directory', 'input files', 'corpus_stats', 'terms', 'parsed_links', 'unique_links', 'unique_words', 'unique_terms', 'word-term_pairs', 'corpus_stats_file', 'category_learner', 'vector_space_dim', 'silhouette', 'inertia', 'generalization', 'cat_tree_file', 'grammar_file', 'grammar_clusters', 'grammar_rules', 'finish', 'grammar_learn_time'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from collections import OrderedDict\n",
    "re.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Corpus statistics: `re['corpus_stats']`  ⇒  `corpus_stats.txt` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:23:59.381904Z",
     "start_time": "2019-02-22T08:23:59.377314Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Number of sentences    ', 12],\n",
       " ['Maximum sentence length', 3],\n",
       " ['Average sentence length', 3],\n",
       " ['Number of unique words in sentences', 13],\n",
       " ['Number of unique parsed words      ', 13],\n",
       " ['Number of unique non-parsed [words]', 0],\n",
       " ['Number of unique linked words      ', 13],\n",
       " ['Number of unique non-linked words  ', 0],\n",
       " ['Total  words count in sentences    ', 36],\n",
       " ['Parsed words count in sentences    ', 36],\n",
       " ['Non-parsed [words] in sentences    ', 0],\n",
       " ['Non-linked words (excl.non-parsed) ', 0],\n",
       " ['Average word count ', 3],\n",
       " ['Unique links number', 19],\n",
       " ['Total  links count ', 24],\n",
       " ['Average link count ', 1.3],\n",
       " ['Average links per linked word', 2],\n",
       " ['Unique connectors number', 17],\n",
       " ['Total  connectors count ', 48],\n",
       " ['Average connector count ', 2.8],\n",
       " ['Unique disjuncts number', 16],\n",
       " ['Total  disjuncts count ', 36],\n",
       " ['Average disjunct count ', 2.2],\n",
       " ['Average disjunct length', 1.3],\n",
       " ['Maximum disjunct length', 2],\n",
       " ['Unique seeds number', 31],\n",
       " ['Total  seeds count ', 36],\n",
       " ['Average seed count ', 1.2]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re['corpus_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:25:50.769076Z",
     "start_time": "2019-02-22T08:25:50.765180Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/obaskov/py/language-learning/output/Grammar_Learner_Tutorial_2019-02-22/1st_test/corpus_stats.txt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re['corpus_stats_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:26:00.738042Z",
     "start_time": "2019-02-22T08:26:00.729970Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences    \t12\n",
      "Maximum sentence length\t3\n",
      "Average sentence length\t3\n",
      "Number of unique words in sentences\t13\n",
      "Number of unique parsed words      \t13\n",
      "Number of unique non-parsed [words]\t0\n",
      "Number of unique linked words      \t13\n",
      "Number of unique non-linked words  \t0\n",
      "Total  words count in sentences    \t36\n",
      "Parsed words count in sentences    \t36\n",
      "Non-parsed [words] in sentences    \t0\n",
      "Non-linked words (excl.non-parsed) \t0\n",
      "Average word count \t3\n",
      "Unique links number\t19\n",
      "Total  links count \t24\n",
      "Average link count \t1.3\n",
      "Average links per linked word\t2\n",
      "Unique connectors number\t17\n",
      "Total  connectors count \t48\n",
      "Average connector count \t2.8\n",
      "Unique disjuncts number\t16\n",
      "Total  disjuncts count \t36\n",
      "Average disjunct count \t2.2\n",
      "Average disjunct length\t1.3\n",
      "Maximum disjunct length\t2\n",
      "Unique seeds number\t31\n",
      "Total  seeds count \t36\n",
      "Average seed count \t1.2\n"
     ]
    }
   ],
   "source": [
    "with open(re['corpus_stats_file'], 'r') as f: lines = f.read().splitlines()\n",
    "for line in lines[:]: print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Response beyond corpus_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:26:38.717813Z",
     "start_time": "2019-02-22T08:26:38.708222Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': '2019-02-22 08:23:19 UTC',\n",
       " 'learn_grammar': 'v.0.7.81231',\n",
       " 'project_directory': '/home/obaskov/py/language-learning/output/Grammar_Learner_Tutorial_2019-02-22/1st_test',\n",
       " 'terms': 'disjuncts',\n",
       " 'parsed_links': 36,\n",
       " 'unique_links': 31,\n",
       " 'unique_words': 13,\n",
       " 'unique_terms': 16,\n",
       " 'word-term_pairs': 31,\n",
       " 'corpus_stats_file': '/home/obaskov/py/language-learning/output/Grammar_Learner_Tutorial_2019-02-22/1st_test/corpus_stats.txt',\n",
       " 'category_learner': 'v.0.7.81231',\n",
       " 'vector_space_dim': 2,\n",
       " 'silhouette': 0.8974816894026034,\n",
       " 'inertia': 0.004335897519749409,\n",
       " 'generalization': 'none: off',\n",
       " 'cat_tree_file': '/home/obaskov/py/language-learning/output/Grammar_Learner_Tutorial_2019-02-22/1st_test/4_cat_tree.txt',\n",
       " 'grammar_file': '/home/obaskov/py/language-learning/output/Grammar_Learner_Tutorial_2019-02-22/1st_test/dict_4C_2019-02-22_0007.4.0.dict',\n",
       " 'grammar_clusters': 4,\n",
       " 'grammar_rules': 4,\n",
       " 'finish': '2019-02-22 08:23:19 UTC',\n",
       " 'grammar_learn_time': '00:00:00'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:v for k,v in re.items() if type(v) is not list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Category tree: `re['cat_tree_file']`  ⇒  `cat_tree.txt` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:32:28.683535Z",
     "start_time": "2019-02-22T08:32:28.678698Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/obaskov/py/language-learning/output/Grammar_Learner_Tutorial_2019-02-22/1st_test/4_cat_tree.txt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re['cat_tree_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:32:33.129533Z",
     "start_time": "2019-02-22T08:32:33.122976Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\t0\t1\t0\teagle fin herring parrot tuna wing\t0 0 0 0 0 0\n",
      "C\t0\t2\t0\tbird extremity fish\t0 0 0\n",
      "D\t0\t3\t0\tisa\t0\n",
      "E\t0\t4\t0\tfeather has scale\t0 0 0\n"
     ]
    }
   ],
   "source": [
    "with open(re['cat_tree_file'], 'r') as f: lines = f.read().splitlines()\n",
    "for line in lines[:]: print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Link Grammar file: `re['grammar_file']`  ⇒  `dict...dict` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:36:23.227354Z",
     "start_time": "2019-02-22T08:36:23.223597Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/obaskov/py/language-learning/output/Grammar_Learner_Tutorial_2019-02-22/1st_test/dict_4C_2019-02-22_0007.4.0.dict'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re['grammar_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T08:36:27.983382Z",
     "start_time": "2019-02-22T08:36:27.975858Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Grammar Learner v.0.7 2019-02-22 08:23:19 UTC\n",
      "<dictionary-version-number>: V0v0v7+;\n",
      "<dictionary-locale>: EN4us+;\n",
      "\n",
      "% B\n",
      "\"eagle\" \"fin\" \"herring\" \"parrot\" \"tuna\" \"wing\":\n",
      "(BD+) or (BE+) or (EB-);\n",
      "\n",
      "% C\n",
      "\"bird\" \"extremity\" \"fish\":\n",
      "(DC-);\n",
      "\n",
      "% D\n",
      "\"isa\":\n",
      "(BD- & DC+);\n",
      "\n",
      "% E\n",
      "\"feather\" \"has\" \"scale\":\n",
      "(BE- & EB+) or (BE- & EE+) or (EE-);\n",
      "\n",
      "<UNKNOWN-WORD>: XXX+;\n",
      "\n",
      "% 4 word clusters, 4 Link Grammar rules.\n"
     ]
    }
   ],
   "source": [
    "with open(re['grammar_file'], 'r') as f: lines = f.read().splitlines()\n",
    "for line in lines[:]: print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Turtle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[github.com/singnet/language-learning/notebooks/](https://github.com/singnet/language-learning/blob/master/notebooks)  ⇒  [POC-Turtle-LG-5.5.1-2018-11-08.ipynb](https://github.com/singnet/language-learning/blob/master/notebooks/POC-Turtle-LG-5.5.1-2018-11-08.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Grammar Learner parameters: kwargs\n",
    "[github.com/singnet/language-learning/src/grammar_learner/README.md](https://github.com/singnet/language-learning/blob/master/src/grammar_learner/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T07:47:39.946434Z",
     "start_time": "2019-02-22T07:47:38.682Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kwargs = {                              # defaults:\n",
    "    # input and output files and paths:\n",
    "    'input_parses'      : <input>   ,   # path to directory with input parses\n",
    "    'output_grammar'    : <output>  ,   # filename or path to store Link Grammar .dict file\n",
    "    # parsing:\n",
    "    'max_sentence_length'   :   99  ,   # filter: max number of parsed words in sentences used for learning\n",
    "    'max_unparsed_words'    :   0   ,   # filter: max number of not parsed words allowed in a sentence\n",
    "    'left_wall'     :   ''          ,   # '','none' - don't use / 'LEFT-WALL' - replace ###LEFT-WALL### tag with 'LEFT-WALL'\n",
    "    'period'        :   False       ,   # use full stop - end of sentence in links learning\n",
    "    # word (vector) space:\n",
    "    'word_space'    :   'embeddings',   # 'embeddings' / 'discrete' / sparse -- see comments below\n",
    "    'context'       :   2           ,   # 1: connectors / 2: disjuncts; \n",
    "    # 'embeddings' 'word_space': \n",
    "    'dim_reduction' :   'svd'       ,   # 'svd' / 'none' for 'discrete', 'sparse' word_space\n",
    "    'dim_max'       :   100         ,   # max vector space dimensionality for SVD\n",
    "    'sv_min'        :   0.1         ,   # minimal singular value (fraction of the max value)\n",
    "    # clustering:\n",
    "    'clustering'    :   'kmeans'    ,   # 'kmeans' / 'group' / 'agglomerative'... -- see comments below\n",
    "    'cluster_range' :   [2,50,1,1]  ,   # min, max, step, repeat / other options described below\n",
    "    'cluster_criteria'  : 'silhouette', # optimal clustering criteria (legacy for 'kmeans' 'clustering')\n",
    "    'clustering_metric' : ['silhouette', 'cosine'], # new setting (October 2018) -- comments below\n",
    "    # grammar induction and generalization:\n",
    "    'grammar_rules'         : 2     ,   # 1: 'connectors' / 2 - 'disjuncts'\n",
    "    'rules_generalization'  : 'off' ,   # 'off' / 'hierarchical' / 'jaccard' -- see comments below \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Closer to reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Basic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T09:36:44.610387Z",
     "start_time": "2019-02-22T09:36:44.588631Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-22 09:36:44 UTC :: module_path: /home/obaskov/py/language-learning\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path: sys.path.append(module_path)\n",
    "from src.grammar_learner.learner import learn\n",
    "from src.grammar_learner.utl import UTC, test_stats\n",
    "from src.grammar_learner.read_files import check_dir, check_corpus\n",
    "from src.grammar_learner.write_files import list2file\n",
    "from src.grammar_learner.widgets import html_table\n",
    "from src.grammar_learner.pqa_table import table_rows, params, wide_rows\n",
    "tmpath = module_path + '/tmp/'\n",
    "check_dir(tmpath, True, 'none')\n",
    "start = time.time()\n",
    "runs = (1,1)\n",
    "print(UTC(), ':: module_path:', module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Test corpus settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T09:36:48.627984Z",
     "start_time": "2019-02-22T09:36:48.616928Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-22 09:36:48 UTC \n",
      " /home/obaskov/py/language-learning/output/Grammar_Learner_Tutorial_2019-02-22\n"
     ]
    }
   ],
   "source": [
    "corpus = 'CDS' # 'Child Directed Speech'\n",
    "dataset = 'LG-E-clean'\n",
    "kwargs = {\n",
    "    'corpus'        :   corpus      ,\n",
    "    'dataset'       :   dataset     ,\n",
    "    'left_wall'     :   ''          ,\n",
    "    'period'        :   False       ,\n",
    "    'context'       :   2           ,\n",
    "    'min_word_count':   1           ,\n",
    "    'min_link_count':   1           ,\n",
    "    'word_space'    :   'sparse'    ,\n",
    "    'clustering'    :   ('mean_shift', 2),\n",
    "    'clustering_metric' : ['silhouette', 'cosine'],\n",
    "    'cluster_range' :   [0]         ,\n",
    "    'top_level'     :   0.01        ,\n",
    "    'grammar_rules' :   2           ,\n",
    "    'max_disjuncts' :   1000000     ,\n",
    "    'stop_words'    :   []          ,\n",
    "    'tmpath'        :   ''          ,\n",
    "    'verbose'       :   'log+'      ,\n",
    "    'template_path' :   'poc-turtle',\n",
    "    'linkage_limit' :   1000        }\n",
    "print(UTC(), '\\n', out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Table: `pqa_table.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T09:38:29.547068Z",
     "start_time": "2019-02-22T09:38:17.769088Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean shift clustering, bandwitdth = 2\n",
      "cd: [[0 0 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "mean shift labels: [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87   0  88  89\n",
      "  90  91  92  93  94  95  96  97   0  98  99 100   0 101 102 103 104 105\n",
      " 106 107 108 109 110 111 112 113 114 115 116 117 118 119   0 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136   0 137 138 139\n",
      " 140 141 142 143   0 144 145 146 147 148 149 150 151 152 153 154 155   0\n",
      " 156 157 158 159 160 161   0 162 163   0 164 165 166 167   0 168 169 170\n",
      " 171   0 172 173   0   0   0   0 174 175 176   0 177 178 179 180 181 182\n",
      " 183   0 184   0 185 186 187 188   0 189   0 190 191 192 193 194 195 196\n",
      " 197 198   0 199 200 201   0   0   0 202 203 204 205   0 206 207   0   0\n",
      " 208 209 210 211 212   0   0 213 214 215 216   0   0   0   0 217 218 219\n",
      "   0 220 221 222   0 223 224   0   0   0 225   0 226   0 227   0 228 229\n",
      " 230   0 231   0   0 232   0 233   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "mean shift centroids: [[0.         0.06779661 0.01694915 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [1.         0.         1.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "mean shift clustering, bandwitdth = 2\n",
      "cd: [[0 0 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "mean shift labels: [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87   0  88  89\n",
      "  90  91  92  93  94  95  96  97   0  98  99 100   0 101 102 103 104 105\n",
      " 106 107 108 109 110 111 112 113 114 115 116 117 118 119   0 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136   0 137 138 139\n",
      " 140 141 142 143   0 144 145 146 147 148 149 150 151 152 153 154 155   0\n",
      " 156 157 158 159 160 161   0 162 163   0 164 165 166 167   0 168 169 170\n",
      " 171   0 172 173   0   0   0   0 174 175 176   0 177 178 179 180 181 182\n",
      " 183   0 184   0 185 186 187 188   0 189   0 190 191 192 193 194 195 196\n",
      " 197 198   0 199 200 201   0   0   0 202 203 204 205   0 206 207   0   0\n",
      " 208 209 210 211 212   0   0 213 214 215 216   0   0   0   0 217 218 219\n",
      "   0 220 221 222   0 223 224   0   0   0 225   0 226   0 227   0 228 229\n",
      " 230   0 231   0   0 232   0 233   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "mean shift centroids: [[0.         0.06779661 0.01694915 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [1.         0.         1.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overal execution:   0%|          | 0/3037 [00:00<?, ?it/s]\n",
      "Overal execution: 100%|██████████| 3037/3037 [00:01<00:00, 2257.56it/s]s]\u001b[A\n",
      "CDS-LG-English-clean.ull: 100%|██████████| 3037/3037 [00:01<00:00, 2362.26sentences/s]\u001b[A\n",
      "Overal execution: 100%|██████████| 3037/3037 [00:01<00:00, 2257.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>Line</td><td>Corpus</td><td>Parsing</td><td>Space</td><td>Linkage</td><td>Affinity</td><td>G12n</td><td>Threshold</td><td>Rules</td><td>MWC</td><td>NN</td><td>SI</td><td>PA</td><td>PQ</td><td>F1</td><td>Top 5 cluster sizes</td></tr><tr><td>1.1</td><td>CDS</td><td>LG-E-clean</td><td>dMLEd</td><td>mean_shift</td><td>---</td><td>none</td><td>---</td><td>234</td><td>1</td><td>---</td><td>0.0</td><td>100%</td><td>98%</td><td>0.99</td><td>[68, 1, 0]</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dictionary: 301 words, grammar learn time: 00:00:10, grammar test time: 00:00:01\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "from src.grammar_learner.pqa_table import table_rows, params, wide_rows\n",
    "corpus  = 'CDS' # 'Child Directed Speech'\n",
    "dataset = 'LG-E-clean'\n",
    "rp = module_path + '/data/' + corpus + '/' + dataset\n",
    "cp = rp  # corpus path = reference_path\n",
    "# kwargs['reference_path'] = module_path + '/data/CDS/LG-E-clean'\n",
    "lines = [['1.1', corpus, dataset, 0, 0, 'none']]\n",
    "a, _, header, log, rules = wide_rows(lines, out_dir, cp, rp, runs, **kwargs)\n",
    "display(html_table([header] + a)); print(test_stats(log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Mutlti-line table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T09:41:49.287383Z",
     "start_time": "2019-02-22T09:41:03.223301Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# lines = [['1.1', corpus, dataset, 0, 0, 'none']]\n",
    "lines = [\n",
    "    [33, 'CDS' , 'LG-E-551'          ,0,0, 'none' ], \n",
    "    [34, 'CDS' , 'LG-E-551'          ,0,0, 'rules'], \n",
    "    [35, 'CDS' , 'R=6-W=6:R-MW=+1:R' ,0,0, 'none' ], \n",
    "    [36, 'CDS' , 'R=6-W=6:R-MW=+1:R' ,0,0, 'rules']]\n",
    "a, _, header, log, rules = wide_rows(lines, out_dir, cp, rp, runs, **kwargs)\n",
    "display(html_table([header] + a)); print(test_stats(log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T09:41:49.296281Z",
     "start_time": "2019-02-22T09:41:49.289642Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>Line</td><td>Corpus</td><td>Parsing</td><td>Space</td><td>Linkage</td><td>Affinity</td><td>G12n</td><td>Threshold</td><td>Rules</td><td>MWC</td><td>NN</td><td>SI</td><td>PA</td><td>PQ</td><td>F1</td><td>Top 5 cluster sizes</td></tr><tr><td>33</td><td>CDS</td><td>LG-E-551</td><td>dMLEd</td><td>mean_shift</td><td>---</td><td>none</td><td>---</td><td>234</td><td>1</td><td>---</td><td>0.0</td><td>100%</td><td>98%</td><td>0.99</td><td>[68, 1, 0]</td></tr><tr><td>34</td><td>CDS</td><td>LG-E-551</td><td>dMLEd</td><td>mean_shift</td><td>---</td><td>rules</td><td>---</td><td>234</td><td>1</td><td>---</td><td>0.0</td><td>100%</td><td>98%</td><td>0.99</td><td>[68, 1, 0]</td></tr><tr><td>35</td><td>CDS</td><td>R=6-W=6:R-MW=+1:R</td><td>dMLEd</td><td>mean_shift</td><td>---</td><td>none</td><td>---</td><td>234</td><td>1</td><td>---</td><td>0.0</td><td>100%</td><td>98%</td><td>0.99</td><td>[68, 1, 0]</td></tr><tr><td>36</td><td>CDS</td><td>R=6-W=6:R-MW=+1:R</td><td>dMLEd</td><td>mean_shift</td><td>---</td><td>rules</td><td>---</td><td>234</td><td>1</td><td>---</td><td>0.0</td><td>100%</td><td>98%</td><td>0.99</td><td>[68, 1, 0]</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dictionary: 301 words, grammar learn time: 00:00:10, grammar test time: 00:00:01\n"
     ]
    }
   ],
   "source": [
    "display(html_table([header] + a)); print(test_stats(log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Real \"Child Directed Speech\" tests ~ 3 hours @ 6 cores of 12-core CPU\n",
    "[http://langlearn.singularitynet.io/data/clustering_2019/html/Child-Directed-Speech-2019-01-03.html](http://langlearn.singularitynet.io/data/clustering_2019/html/Child-Directed-Speech-2019-01-03.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## More Jupyter notebook samples: Github\n",
    "[GitHub.com/SingNET/Language-Learning/Notebooks](https://github.com/singnet/language-learning/tree/master/notebooks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Grammar Learner test archives\n",
    "2018 :: [http://langlearn.singularitynet.io/data/clustering_2018/](http://langlearn.singularitynet.io/data/clustering_2019/)  ⇒ [html](http://langlearn.singularitynet.io/data/clustering_2018/html)  \n",
    "2019 :: [http://langlearn.singularitynet.io/data/clustering_2019/](http://langlearn.singularitynet.io/data/clustering_2019/)  ⇒ [html](http://langlearn.singularitynet.io/data/clustering_2019/html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try yourself: [GitHub.com/SingNET/Language-Learning](https://github.com/singnet/language-learning)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ull]",
   "language": "python",
   "name": "conda-env-ull-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
